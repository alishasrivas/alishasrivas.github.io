<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="/css/style.css">
    <link rel="stylesheet" href="/papers/OWL/owl.css">
    <title> 🦉 OWL: Probing Cross-Lingual Recall of Memorized Texts via World Literature</title>
</head>
<body>
    <div class="container">
        <header>
            <nav>
                <a href="/" class="nav-link home-corner">← Home</a>
            </nav>
        </header>

        <main>
            <section class="hero" style="margin-top: 6em;">
                <h1 style="margin-bottom: 0.5em;">🦉 OWL: Probing Cross-Lingual Recall of Memorized Texts via World Literature</h1>
                <div class="authors">
                    <span>
                        <sup>1</sup><a href="http://alishasrivastava.com#">Alisha Srivastava*</a>,
                        <sup>1</sup><a href="https://emirkaan5.github.io">Emir Kaan Korukluoglu*</a>,
                        <sup>1</sup><a href="#">Minh Nhat Le*</a>,
                        <sup>1</sup><a href="#">Duyen Tran</a>,
                        <sup>2</sup><a href="https://chtmp223.github.io">Chau Minh Pham</a>
                        <sup>3</sup><a href="https://marzenakrp.github.io">Marzena Karpinska</a>
                        <sup>2</sup><a href="https://www.cs.umd.edu/~miyyer/">Mohit Iyyer</a>
                    </span>
                    <span style="margin-top: 2em; display: block;">
                        <sup>1</sup>University of Massachusetts Amherst,
                        <sup>2</sup>University of Maryland College Park,
                        <sup>3</sup>Microsoft
                    </span>
                </div>
                <div class="owl-slideshow" style="margin: 0 auto;">
                    <img class="owl-slide-img" src="https://raw.githubusercontent.com/alishasrivas/alishasrivas.github.io/main/papers/OWL/figures/All%20Results.png" style="display:none;">
                    <img class="owl-slide-img" src="https://raw.githubusercontent.com/alishasrivas/alishasrivas.github.io/main/papers/OWL/figures/Overview.png" style="display:none;">
                    <img class="owl-slide-img" src="https://raw.githubusercontent.com/alishasrivas/alishasrivas.github.io/main/papers/OWL/figures/DP.jpeg" style="display:none;">
                    <img class="owl-slide-img" src="https://raw.githubusercontent.com/alishasrivas/alishasrivas.github.io/main/papers/OWL/figures/Pertubations.jpeg" style="display:none;">
                    <img class="owl-slide-img" src="https://raw.githubusercontent.com/alishasrivas/alishasrivas.github.io/main/papers/OWL/figures/Multimodal.jpeg" style="display:none;">
                    <img class="owl-slide-img" src="https://raw.githubusercontent.com/alishasrivas/alishasrivas.github.io/main/papers/OWL/figures/quantization.jpeg" style="display:block;">
                    <button class="owl-slide-btn prev" onclick="owlPlusSlides(-1)">&#10094;</button>
                    <button class="owl-slide-btn next" onclick="owlPlusSlides(1)">&#10095;</button>
                    <div class="owl-slide-caption" id="owl-slide-caption">Placeholder caption 1</div>
                </div>
                <script>
                let owlSlideIndex = 0;
                const owlCaptions = [
                  "LLMs memorize novels 📚 in English. But what about existing translations? Or translations into new languages?<br><br>Our 🦉OWL dataset (31K/10 languages) shows GPT4o recognizes books:<br>92% English<br>83% official translations<br>69% unseen translations<br>75% as audio (EN)",
                  "OWL has aligned excerpts from 20 EN novels, with translations in ES 🇪🇸, TR 🇹🇷, VI 🇻🇳 + 6 new low-resource languages 🌍 & EN audio 🔊<br><br>We probe LLMs to:<br>1️⃣ identify book/author (direct probing)<br>2️⃣ predict masked names (name cloze)<br>3️⃣ generate continuation (prefix probing)",
                  "LLMs can identify book titles and authors across languages - even those not seen during pre-training:<br><br>63.8% accuracy on English passages<br>47.2% on official translations (Spanish, Turkish, Vietnamese) 🇪🇸 🇹🇷 🇻🇳<br>36.5% on completely unseen languages like Sesotho & Maithili 🌍",
                  "What if we perturb the text?<br><br>🧩 shuffled text<br>🎭 masked character names<br>🙅🏻‍♀️ passages w/o characters<br><br>🚨Reduce accuracy with the degree varying across languages BUT models can still identify the books better than newly published books (0.1%) 🚨",
                  "🔊 LLMs can transfer knowledge across modalities (Text → Audio).<br><br>On GPT-4o-Audio vs Text:<br>📖 Direct Probing: 75.5% (vs. 92.3%)<br>👤 Name Cloze: 15.9% (vs. 38.6%)<br>✍️ Prefix Probing: 27.2% (vs. 22.6%)<br><br>Qwen-Omni shows similar trends but lower accuracy.",
                  "🧮 Does quantization (GPTQ) impact cross-lingual knowledge transfer?<br><br>LLaMA-3.1-70B: 4-bit > 8-bit ⏩ accuracy drops MORE at 8-bit (up to 25%)<br>LLaMA-3.1-8B: 8-bit > 4-bit ⏩ accuracy drops MORE at 4-bit (up to 8%)<br><br>�� Bigger models aren't always more robust to quantization."
                ];
                showOwlSlides(owlSlideIndex);
                function owlPlusSlides(n) {
                    showOwlSlides(owlSlideIndex += n);
                }
                function showOwlSlides(n) {
                    let slides = document.getElementsByClassName("owl-slide-img");
                    if (n >= slides.length) {owlSlideIndex = 0;}
                    if (n < 0) {owlSlideIndex = slides.length - 1;}
                    for (let i = 0; i < slides.length; i++) {
                        slides[i].style.display = "none";
                    }
                    slides[owlSlideIndex].style.display = "block";
                    document.getElementById("owl-slide-caption").innerHTML = owlCaptions[owlSlideIndex];
                }
                </script>
                <div class="links" style="justify-content: center; margin: 2em 0 0 0;">
                    <a href="https://huggingface.co/alishasrivas" class="custom-button" target="_blank">
                        <img src="/buttons/huggingface.svg" alt="Dataset" class="button-icon"> Dataset
                    </a>
                    <a href="https://github.com/emirkaan5/OWL" class="custom-button" target="_blank">
                        <img src="/buttons/github.png" alt="Code" class="button-icon"> Code
                    </a>
                    <a href="https://arxiv.org/abs/2505.22945" class="custom-button" target="_blank">
                        <img src="/buttons/arxiv.svg" alt="Paper" class="button-icon"> Paper
                    </a>
                </div>
                <div class="contact" style="margin-top: 2em;">
                    <p>Contact: <a href="mailto:alishasrivas@umass.edu">alishasrivas@umass.edu</a></p>
                </div>
                <hr class="section-divider">
            </section>

            <section class="experiments">
                <h2>Experiments</h2>
                <div class="results-table">
                    <div class="main-figure">
                        <img src="https://github.com/alishasrivas/alishasrivas.github.io/blob/main/OWL%20Experiments.png?raw=true" alt="OWL Experiments Figure" class="main-figure-img">
                    </div>
                    <p>We probe LLMs to identify books and authors across languages, predict masked character names, and generate continuations via memorization as knowledge accquisiton.</p>
                    <p>Non-trivial performance across all tasks and languages, even for low-resource languages, reveals that LLMs do exhibit cross-lingual knowledge transfer. ✅</p>
                </div>
            </section>
            <hr class="section-divider">
            <section class="dataset">
                <h2>Constructing 🦉 OWL</h2>
                <div class="pipeline-figure">
                    <img src="https://github.com/alishasrivas/alishasrivas.github.io/blob/main/OWL%20Pipeline.png?raw=true" alt="OWL Pipeline Figure" class="main-figure-img">
                </div>
                <p>If you'd like to construct your own dataset from our pipeline, you can see our code <a href="https://github.com/emirkaan5/OWL/tree/main" target="_blank">here</a>.</p>
                <p>In the future, we plan to release a Python library which will allow you to construct your own multilingual & multimodal OWL dataset from any text corpus. </p>
            </section>
            <hr class="section-divider">
            <section class="acknowledgements">
                <h2>Acknowledgements</h2>
                <p>I'd like to thank my advisor, <a href="https://www.cs.umd.edu/~miyyer/">Mohit Iyyer</a>, and mentors <a href="https://marzenakrp.github.io">Marzena Karpinska</a> and <a href="https://chtmp223.github.io">Chau Minh Pham</a> for their guidance and support. I'd also like to thank the UMass Natural Language Processing Group for their feedback and funding. I'd also like to thank <a href="https://www.cics.umass.edu/about/directory/neena-thota">Professor Neena Thota</a> and the <a href="https://sites.google.com/umass.edu/ersp-cics">Early Research Scholars Program</a> at the University of Massachusetts Amherst for encouraging me into academia.</p>
            </section>
        </main>
    </div>
    <footer class="footnote">Developed by Alisha Srivastava</footer>
</body>
</html> 